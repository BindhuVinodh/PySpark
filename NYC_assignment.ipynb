{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"NYC Parking tkt\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the input data\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|    5092469481| GZH7067|                NY|2016-07-10 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|         0143A|\n",
      "|    5092451658| GZH7067|                NY|2016-07-08 00:00:00|             7|             SUBN|       TOYOT|                 0|              0|         0400P|\n",
      "|    4006265037| FZX9232|                NY|2016-08-23 00:00:00|             5|             SUBN|        FORD|                 0|              0|         0233P|\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|\n",
      "|    7868300310| 37033JV|                NY|2016-11-21 00:00:00|            69|             DELV|       INTER|                13|             13|         0555P|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13 00:00:00|             7|             SUBN|       ME/BE|                 0|              0|         0852P|\n",
      "|    1413609545|  X20DCM|                NJ|2016-08-03 00:00:00|            40|              SDN|       TOYOT|                71|             71|         0215A|\n",
      "|    4628525523|  326SF9|                MA|2016-12-21 00:00:00|            36|               UT|         BMW|                 0|              0|         0758A|\n",
      "|    4627113330| HCA5464|                NY|2016-11-21 00:00:00|            36|             SUBN|       DODGE|                 0|              0|         1005A|\n",
      "|    4006478550| VAD7274|                VA|2016-10-05 00:00:00|             5|               4D|         BMW|                 0|              0|         0845A|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create year column from Issue date\n",
    "df = df.withColumn('issue_year', F.year(F.col('Issue Date')))\n",
    "df = df.withColumn('issue_month', F.month(F.col('Issue Date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep data only for year=2017\n",
    "df = df.where(F.col('issue_year') == 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the total number of tickets for the year.\n",
    "\n",
    "Assuming the data contains only 1 year of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of summons in a year:  5431918\n"
     ]
    }
   ],
   "source": [
    "#### Find the total number of tickets for the year.\n",
    "\n",
    "##Assuming the data contains only 1 year of data\n",
    "\n",
    "total_tickets_ty = df.select('Summons Number').distinct().count()\n",
    "print(\"Total number of summons in a year: \", total_tickets_ty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##There is a numeric entry '99' in the column, which should be corrected. Replace it with the state having the maximum entries. Provide the number of unique states again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number distinct states:  65\n"
     ]
    }
   ],
   "source": [
    "total_dist_states = df.select('Registration State').distinct().count()\n",
    "print(\"Total number distinct states: \", total_dist_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State with highest tickets count is:  NY\n"
     ]
    }
   ],
   "source": [
    "# find the state with highest frequency\n",
    "highest_frequency_state = df.groupBy('Registration State').agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "highest_frequency_state = highest_frequency_state.orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "highest_frequency_state = highest_frequency_state.collect()[0][0]\n",
    "print('State with highest tickets count is: ', highest_frequency_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number distinct states after replacing 99:  64\n"
     ]
    }
   ],
   "source": [
    "# replace 99 with highest ticket count state and get distinct state count again\n",
    "df = df.replace('99', highest_frequency_state, 'Registration State')\n",
    "\n",
    "total_dist_states = df.select('Registration State').distinct().count()\n",
    "print(\"Total number distinct states after replacing 99: \", total_dist_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How often does each violation code occur? Display the frequency of the top five violation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|Violation Code|ticket_count|\n",
      "+--------------+------------+\n",
      "|21            |768087      |\n",
      "|36            |662765      |\n",
      "|38            |542079      |\n",
      "|14            |476664      |\n",
      "|20            |319646      |\n",
      "+--------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "violation_code_freq = df.groupBy(\"Violation Code\").agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "violation_code_freq = violation_code_freq.orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "violation_code_freq.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. How often does each 'vehicle body type' get a parking ticket? How about the 'vehicle make'? (Hint: Find the top 5 for both.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|Vehicle Body Type|ticket_count|\n",
      "+-----------------+------------+\n",
      "|SUBN             |1883954     |\n",
      "|4DSD             |1547312     |\n",
      "|VAN              |724029      |\n",
      "|DELV             |358984      |\n",
      "|SDN              |194197      |\n",
      "+-----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vehicle_body_freq = df.groupBy(\"Vehicle Body Type\").agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "vehicle_body_freq = vehicle_body_freq.orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "vehicle_body_freq.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|Vehicle Make|ticket_count|\n",
      "+------------+------------+\n",
      "|FORD        |636844      |\n",
      "|TOYOT       |605291      |\n",
      "|HONDA       |538884      |\n",
      "|NISSA       |462017      |\n",
      "|CHEVR       |356032      |\n",
      "+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vehicle_make_freq = df.groupBy(\"Vehicle Make\").agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "vehicle_make_freq = vehicle_make_freq.orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "vehicle_make_freq.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. A precinct is a police station that has a certain zone of the city under its command. Find the (5 highest) frequencies of tickets for each of the following:\n",
    "+ 'Violation Precinct' (This is the precinct of the zone where the violation occurred). Using this, can you draw any insights for parking violations in any specific areas of the city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|Violation Precinct|ticket_count|\n",
      "+------------------+------------+\n",
      "|0                 |925596      |\n",
      "|19                |274445      |\n",
      "|14                |203553      |\n",
      "|1                 |174702      |\n",
      "|18                |169131      |\n",
      "+------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's check in which precinct most tickets were cut\n",
    "\n",
    "violation_pre_freq = df.groupBy(\"Violation Precinct\").agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "violation_pre_freq = violation_pre_freq.orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "violation_pre_freq.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+------------+\n",
      "|Violation Precinct|Vehicle Make|ticket_count|\n",
      "+------------------+------------+------------+\n",
      "|0                 |TOYOT       |136752      |\n",
      "|0                 |HONDA       |111818      |\n",
      "|0                 |NISSA       |106306      |\n",
      "|0                 |FORD        |85597       |\n",
      "|19                |FORD        |55222       |\n",
      "+------------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now let's check what are the top Vehicle-Make and Precinct combination\n",
    "\n",
    "vio_make_pre_freq = df.groupBy(\"Violation Precinct\", \"Vehicle Make\").agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "vio_make_pre_freq = vio_make_pre_freq.orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "vio_make_pre_freq.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##+ 'Issuer Precinct' (This is the precinct that issued the ticket.)\n",
    "Here, you would have noticed that the dataframe has the'Violating Precinct' or 'Issuing Precinct' as '0'. These are erroneous entries. Hence, you need to provide the records for five correct precincts. (Hint: Print the top six entries after sorting.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+\n",
      "|Issuer Precinct|ticket_count|\n",
      "+---------------+------------+\n",
      "|0              |1078406     |\n",
      "|19             |266961      |\n",
      "|14             |200495      |\n",
      "|1              |168740      |\n",
      "|18             |162994      |\n",
      "|114            |144054      |\n",
      "+---------------+------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "issuer_pre_freq = df.groupBy(\"Issuer Precinct\").agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "issuer_pre_freq = issuer_pre_freq.orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "issuer_pre_freq.show(6, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Find the violation code frequencies for three precincts that have issued the most number of tickets. Do these precinct zones have an exceptionally high frequency of certain violation codes? Are these codes common across precincts? \n",
    "(Hint: In the SQL view, use the 'where' attribute to filter among three precincts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|Violation Precinct|\n",
      "+------------------+\n",
      "|0                 |\n",
      "|19                |\n",
      "|14                |\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find top 3 violation precinct\n",
    "violation_pre_freq = df.groupBy(\"Violation Precinct\").agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "violation_pre_freq = violation_pre_freq.orderBy(F.col('ticket_count').desc()).limit(3)\n",
    "\n",
    "violation_pre_freq = violation_pre_freq.select('Violation Precinct')\n",
    "\n",
    "violation_pre_freq.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+------------+\n",
      "|Violation Precinct|Violation Code|ticket_count|\n",
      "+------------------+--------------+------------+\n",
      "|0                 |36            |662765      |\n",
      "|0                 |7             |210174      |\n",
      "|19                |46            |50785       |\n",
      "|0                 |5             |48076       |\n",
      "|14                |14            |45885       |\n",
      "|19                |38            |37483       |\n",
      "|19                |37            |36468       |\n",
      "|14                |69            |30465       |\n",
      "|19                |14            |30376       |\n",
      "|19                |21            |29415       |\n",
      "|14                |31            |22649       |\n",
      "|14                |47            |18691       |\n",
      "|19                |20            |15132       |\n",
      "|19                |40            |11519       |\n",
      "|14                |42            |10027       |\n",
      "|19                |16            |10006       |\n",
      "|14                |46            |8411        |\n",
      "|19                |71            |7567        |\n",
      "|14                |19            |7455        |\n",
      "|19                |19            |7066        |\n",
      "|14                |84            |6749        |\n",
      "|19                |10            |5669        |\n",
      "|14                |82            |5052        |\n",
      "|19                |84            |4928        |\n",
      "|19                |70            |4503        |\n",
      "|14                |40            |3654        |\n",
      "|14                |17            |3569        |\n",
      "|14                |38            |3293        |\n",
      "|19                |18            |3218        |\n",
      "|19                |69            |2910        |\n",
      "|14                |9             |2871        |\n",
      "|14                |20            |2816        |\n",
      "|14                |71            |2764        |\n",
      "|14                |13            |2703        |\n",
      "|14                |48            |2470        |\n",
      "|19                |31            |2090        |\n",
      "|14                |89            |1960        |\n",
      "|14                |50            |1844        |\n",
      "|19                |53            |1769        |\n",
      "|14                |11            |1760        |\n",
      "|14                |79            |1602        |\n",
      "|19                |17            |1589        |\n",
      "|19                |50            |1506        |\n",
      "|14                |70            |1472        |\n",
      "|19                |48            |1469        |\n",
      "|19                |74            |1354        |\n",
      "|14                |10            |1336        |\n",
      "|14                |37            |1267        |\n",
      "|19                |24            |1140        |\n",
      "|14                |64            |1072        |\n",
      "|14                |21            |1053        |\n",
      "|14                |23            |1045        |\n",
      "|14                |53            |964         |\n",
      "|14                |24            |950         |\n",
      "|14                |16            |943         |\n",
      "|19                |42            |903         |\n",
      "|19                |82            |891         |\n",
      "|14                |74            |789         |\n",
      "|19                |47            |706         |\n",
      "|0                 |46            |694         |\n",
      "|14                |35            |678         |\n",
      "|19                |45            |594         |\n",
      "|0                 |14            |592         |\n",
      "|14                |8             |588         |\n",
      "|14                |51            |560         |\n",
      "|19                |51            |555         |\n",
      "|14                |52            |550         |\n",
      "|14                |45            |537         |\n",
      "|19                |9             |497         |\n",
      "|0                 |21            |471         |\n",
      "|19                |13            |450         |\n",
      "|19                |64            |407         |\n",
      "|0                 |40            |339         |\n",
      "|0                 |20            |290         |\n",
      "|0                 |79            |273         |\n",
      "|0                 |19            |272         |\n",
      "|14                |18            |263         |\n",
      "|14                |1             |259         |\n",
      "|14                |3             |259         |\n",
      "|14                |73            |253         |\n",
      "|14                |30            |247         |\n",
      "|14                |78            |225         |\n",
      "|0                 |38            |215         |\n",
      "|14                |26            |212         |\n",
      "|19                |23            |207         |\n",
      "|14                |72            |200         |\n",
      "|19                |78            |197         |\n",
      "|0                 |0             |191         |\n",
      "|0                 |98            |185         |\n",
      "|19                |11            |182         |\n",
      "|14                |85            |152         |\n",
      "|14                |77            |143         |\n",
      "|19                |98            |115         |\n",
      "|14                |83            |108         |\n",
      "|0                 |78            |94          |\n",
      "|19                |75            |92          |\n",
      "|14                |49            |84          |\n",
      "|0                 |45            |81          |\n",
      "|19                |85            |79          |\n",
      "|14                |98            |79          |\n",
      "+------------------+--------------+------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the violation codes for those 3 violation precinct\n",
    "\n",
    "violation_pre_code_freq = df.groupBy(\"Violation Precinct\", \"Violation Code\").agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "violation_pre_code_freq = violation_pre_code_freq.join(violation_pre_freq, on=\"Violation Precinct\", how=\"inner\")\n",
    "\n",
    "violation_pre_code_freq = violation_pre_code_freq.orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "violation_pre_code_freq.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Find out the properties of parking violations across different times of the day:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a way to deal with missing values, if any.\n",
    "(Hint: Check for the null values using 'isNull' under the SQL. Also, to remove the null values, check the 'dropna' command in the API documentation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(x):\n",
    "    try:\n",
    "        return datetime.strptime(x+\"M\", \"%I%M%p\").hour\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "time_udf = F.udf(get_time)\n",
    "\n",
    "time_udf2 = F.udf(get_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Violation Time field is specified in a strange format. Find a way to make this a time attribute that you can use to divide into groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----------+-----------+--------------+---------------------+\n",
      "|Summons Number|Plate ID|Registration State|         Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|issue_year|issue_month|violation_hour|violation_hour_groups|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----------+-----------+--------------+---------------------+\n",
      "|    8478629828| 66623ME|                NY|2017-06-14 00:00:00|            47|             REFG|       MITSU|                14|             14|         1120A|      2017|          6|            11|                    2|\n",
      "|    5096917368| FZD8593|                NY|2017-06-13 00:00:00|             7|             SUBN|       ME/BE|                 0|              0|         0852P|      2017|          6|            20|                    5|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----------+-----------+--------------+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#time_udf = F.udf(lambda x: datetime.strptime(x+\"M\", \"%H%M%p\").hour)\n",
    "\n",
    "df = df.withColumn('violation_hour', time_udf2(F.col('Violation Time')))\n",
    "df = df.withColumn('violation_hour_groups', (F.col('violation_hour')/4).cast('int'))\n",
    "\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----------+-----------+--------------+---------------------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date         |Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|issue_year|issue_month|violation_hour|violation_hour_groups|\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----------+-----------+--------------+---------------------+\n",
      "|8478629828    |66623ME |NY                |2017-06-14 00:00:00|47            |REFG             |MITSU       |14                |14             |1120A         |2017      |6          |11            |8-11                 |\n",
      "|5096917368    |FZD8593 |NY                |2017-06-13 00:00:00|7             |SUBN             |ME/BE       |0                 |0              |0852P         |2017      |6          |20            |20-23                |\n",
      "+--------------+--------+------------------+-------------------+--------------+-----------------+------------+------------------+---------------+--------------+----------+-----------+--------------+---------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_udf = F.udf(lambda x: \"{}-{}\".format(x*4, x*4+3) if type(x) == int else None)\n",
    "\n",
    "df = df.withColumn('violation_hour_groups', \n",
    "                   F.when(F.isnull(F.col('violation_hour_groups'))==False, format_udf(F.col('violation_hour_groups')))\\\n",
    "                   .otherwise(F.lit(None)))\n",
    "\n",
    "df.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide 24 hours into six equal discrete bins of time. Choose the intervals as you see fit. For each of these groups, find the three most commonly occurring violations.\n",
    "(Hint: Use the CASE-WHEN in SQL view to segregate into bins. To find the most commonly occurring violations, you can use an approach similar to the one mentioned in the hint for question 4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------+------------+--------------+\n",
      "|violation_hour_groups|Violation Code|ticket_count|violation_rank|\n",
      "+---------------------+--------------+------------+--------------+\n",
      "|0-3                  |21            |26444       |1             |\n",
      "|0-3                  |40            |22420       |2             |\n",
      "|0-3                  |78            |13737       |3             |\n",
      "|12-15                |38            |240721      |2             |\n",
      "|12-15                |37            |167025      |3             |\n",
      "|12-15                |36            |286284      |1             |\n",
      "|16-19                |38            |102855      |1             |\n",
      "|16-19                |14            |75902       |2             |\n",
      "|16-19                |37            |70345       |3             |\n",
      "|20-23                |7             |26293       |1             |\n",
      "|20-23                |40            |22336       |2             |\n",
      "|20-23                |14            |21045       |3             |\n",
      "|4-7                  |14            |74113       |1             |\n",
      "|4-7                  |40            |60652       |2             |\n",
      "|4-7                  |21            |57894       |3             |\n",
      "|8-11                 |21            |598062      |1             |\n",
      "|8-11                 |36            |348165      |2             |\n",
      "|8-11                 |38            |176570      |3             |\n",
      "+---------------------+--------------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get ticket count for each time group and violation code\n",
    "group_violation_freq = df.groupBy(['violation_hour_groups', 'Violation Code']).agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "# filter top 3 violation code for each of the time groups\n",
    "w = Window.partitionBy('violation_hour_groups').orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "group_violation_freq = group_violation_freq.withColumn('violation_rank', F.dense_rank().over(w))\n",
    "\n",
    "top_group_violation_freq = group_violation_freq.where(F.col('violation_rank')<4)\n",
    "\n",
    "top_group_violation_freq = top_group_violation_freq.orderBy('violation_hour_groups')\n",
    "\n",
    "top_group_violation_freq = top_group_violation_freq.dropna()\n",
    "\n",
    "top_group_violation_freq.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select('Violation Time'). distinct ().orderBy ('violation Time').show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, try another direction. For the three most commonly occurring violation codes, find the most common time of the day (in terms of the bins from the previous part).\n",
    "time_udf = F.udf()#### Now, try another direction. For the three most commonly occurring violation codes, find the most common time of the day (in terms of the bins from the previous part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+------------+\n",
      "|Violation Code|violation_hour_groups|ticket_count|\n",
      "+--------------+---------------------+------------+\n",
      "|38            |12-15                |240721      |\n",
      "|21            |8-11                 |598062      |\n",
      "|36            |8-11                 |348165      |\n",
      "+--------------+---------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get top 3 violation codes\n",
    "\n",
    "w = Window.partitionBy().orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "top3_violation_code_freq = violation_code_freq.withColumn('rank', F.dense_rank().over(w))\n",
    "\n",
    "top3_violation_code_freq = top3_violation_code_freq.where(F.col('rank')<4)\n",
    "\n",
    "top3_violation_code_freq = top3_violation_code_freq.select('Violation Code').distinct()\n",
    "\n",
    "# merge these top violation codes with time group-violation frequency data we created above\n",
    "top3_violation_code_group_freq = top3_violation_code_freq.join(group_violation_freq, on=\"Violation Code\", how=\"inner\")\n",
    "\n",
    "# for each violcation code get top time group\n",
    "w = Window.partitionBy('Violation Code').orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "top3_violation_code_group_freq = top3_violation_code_group_freq.withColumn('violation_rank', F.dense_rank().over(w))\n",
    "\n",
    "top3_violation_code_group_freq = top3_violation_code_group_freq.where(F.col('violation_rank')==1)\n",
    "\n",
    "top3_violation_code_group_freq = top3_violation_code_group_freq.drop('violation_rank')\n",
    "\n",
    "top3_violation_code_group_freq.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Let’s try and find some seasonality in this data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, divide the year into a certain number of seasons, and find the frequencies of tickets for each season. (Hint: Use Issue Date to segregate into seasons.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create seasons\n",
    "number_seasons = 4\n",
    "\n",
    "df = df.withColumn('season', (F.col('issue_month')/number_seasons).cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|season|ticket_count|\n",
      "+------+------------+\n",
      "|0     |2669069     |\n",
      "|1     |2761203     |\n",
      "|2     |1288        |\n",
      "|3     |358         |\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seasons_freq = df.groupBy('season').agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "seasons_freq = seasons_freq.orderBy('season')\n",
    "\n",
    "seasons_freq.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then, find the three most common violations for each of these seasons.\n",
    "(Hint: You can use an approach similar to the one mentioned in the hint for question 4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+------------+--------------+\n",
      "|season|Violation Code|ticket_count|violation_rank|\n",
      "+------+--------------+------------+--------------+\n",
      "|0     |21            |373874      |1             |\n",
      "|0     |36            |348240      |2             |\n",
      "|0     |38            |287000      |3             |\n",
      "|1     |36            |314525      |2             |\n",
      "|1     |38            |255067      |3             |\n",
      "|1     |21            |393957      |1             |\n",
      "|2     |40            |149         |3             |\n",
      "|2     |46            |288         |1             |\n",
      "|2     |21            |212         |2             |\n",
      "|3     |46            |77          |1             |\n",
      "|3     |21            |44          |2             |\n",
      "|3     |40            |44          |2             |\n",
      "|3     |20            |33          |3             |\n",
      "+------+--------------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get ticket count for each time group and violation code\n",
    "season_violation_freq = df.groupBy(['season', 'Violation Code']).agg(F.countDistinct(F.col('Summons Number')).alias('ticket_count'))\n",
    "\n",
    "# filter top 3 violation code for each of the time groups\n",
    "w = Window.partitionBy('season').orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "season_violation_freq = season_violation_freq.withColumn('violation_rank', F.dense_rank().over(w))\n",
    "\n",
    "top_season_violation_freq = season_violation_freq.where(F.col('violation_rank')<4)\n",
    "\n",
    "top_season_violation_freq = top_season_violation_freq.orderBy('season')\n",
    "\n",
    "top_season_violation_freq.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. The fines collected from all the instances of parking violation constitute a source of revenue for the NYC Police Department. Let’s take an example of estimating this for the three most commonly occurring codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----+\n",
      "|Violation Code|ticket_count|rank|\n",
      "+--------------+------------+----+\n",
      "|21            |768087      |1   |\n",
      "|36            |662765      |2   |\n",
      "|38            |542079      |3   |\n",
      "+--------------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing top 3 violation codes\n",
    "\n",
    "w = Window.partitionBy().orderBy(F.col('ticket_count').desc())\n",
    "\n",
    "top3_violation_code_freq = violation_code_freq.withColumn('rank', F.dense_rank().over(w))\n",
    "\n",
    "top3_violation_code_freq = top3_violation_code_freq.where(F.col('rank')<4)\n",
    "\n",
    "top3_violation_code_freq.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
